{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Before you use this template\n",
        "\n",
        "This template is just a recommended template for project Report. It only considers the general type of research in our paper pool. Feel free to edit it to better fit your project. You will iteratively update the same notebook submission for your draft and the final submission. Please check the project rubriks to get a sense of what is expected in the template.\n",
        "\n",
        "---\n",
        "\n",
        "# FAQ and Attentions\n",
        "* Copy and move this template to your Google Drive. Name your notebook by your team ID (upper-left corner). Don't eidt this original file.\n",
        "* This template covers most questions we want to ask about your reproduction experiment. You don't need to exactly follow the template, however, you should address the questions. Please feel free to customize your report accordingly.\n",
        "* any report must have run-able codes and necessary annotations (in text and code comments).\n",
        "* The notebook is like a demo and only uses small-size data (a subset of original data or processed data), the entire runtime of the notebook including data reading, data process, model training, printing, figure plotting, etc,\n",
        "must be within 8 min, otherwise, you may get penalty on the grade.\n",
        "  * If the raw dataset is too large to be loaded  you can select a subset of data and pre-process the data, then, upload the subset or processed data to Google Drive and load them in this notebook.\n",
        "  * If the whole training is too long to run, you can only set the number of training epoch to a small number, e.g., 3, just show that the training is runable.\n",
        "  * For results model validation, you can train the model outside this notebook in advance, then, load pretrained model and use it for validation (display the figures, print the metrics).\n",
        "* The post-process is important! For post-process of the results,please use plots/figures. The code to summarize results and plot figures may be tedious, however, it won't be waste of time since these figures can be used for presentation. While plotting in code, the figures should have titles or captions if necessary (e.g., title your figure with \"Figure 1. xxxx\")\n",
        "* There is not page limit to your notebook report, you can also use separate notebooks for the report, just make sure your grader can access and run/test them.\n",
        "* If you use outside resources, please refer them (in any formats). Include the links to the resources if necessary."
      ],
      "metadata": {
        "id": "j01aH0PR4Sg-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Notebook to Google Drive\n",
        "Upload the data, pretrianed model, figures, etc to your Google Drive, then mount this notebook to Google Drive. After that, you can access the resources freely.\n",
        "\n",
        "Instruction: https://colab.research.google.com/notebooks/io.ipynb\n",
        "\n",
        "Example: https://colab.research.google.com/drive/1srw_HFWQ2SMgmWIawucXfusGzrj1_U0q\n",
        "\n",
        "Video: https://www.youtube.com/watch?v=zc8g8lGcwQU"
      ],
      "metadata": {
        "id": "dlv6knX04FiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sfk8Zrul_E8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "431b4296-ee3b-4ef3-f455-4e6fb2d219a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n"
      ],
      "metadata": {
        "id": "MQ0sNuMePBXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The analysis of clinical notes to predict patient outcomes is a critical area in healthcare informatics. Current methodologies often struggle with the inherent multi-level sequential structure and temporal spacing of clinical notes. This project aims to reproduce the study conducted by Zhang et al. [1], which addresses these challenges using a novel transformer-based hierarchical architecture, termed FTL-Trans, for predicting patient health states from clinical notes."
      ],
      "metadata": {
        "id": "UYu2LO5I0OiH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scope of Reproducibility:\n",
        "\n",
        "List hypotheses from the paper you will test and the corresponding experiments you will run.\n",
        "\n",
        "\n",
        "1.   Hypothesis 1: The FTL-Trans model will outperform baseline model BERT [2] in predicting patient outcomes using clinical notes.\n",
        "2.   Hypothesis 2: Incorporating both sequential and temporal information will enhance the model's predictive accuracy and AUROC scores.\n",
        "\n"
      ],
      "metadata": {
        "id": "uygL9tTPSVHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# no code is required for this section\n",
        "'''\n",
        "if you want to use an image outside this notebook for explanaition,\n",
        "you can upload it to your google drive and show it with OpenCV or matplotlib\n",
        "'''\n",
        "# mount this notebook to your google drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# define dirs to workspace and data\n",
        "img_dir = '/content/gdrive/My Drive/Colab Notebooks/<path-to-your-image>'\n",
        "\n",
        "import cv2\n",
        "img = cv2.imread(img_dir)\n",
        "cv2.imshow(\"Title\", img)\n"
      ],
      "metadata": {
        "id": "rRksCB1vbYwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology\n",
        "\n",
        "This methodology is the core of your project. It consists of run-able codes with necessary annotations to show the expeiment you executed for testing the hypotheses.\n",
        "\n",
        "The methodology at least contains two subsections **data** and **model** in your experiment."
      ],
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import  packages you need\n",
        "import numpy as np\n",
        "from google.colab import drive\n"
      ],
      "metadata": {
        "id": "yu61Jp1xrnKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Data\n",
        "Data includes raw data (MIMIC III tables), descriptive statistics (our homework questions), and data processing (feature engineering).\n",
        "  * Source of the data: where the data is collected from; if data is synthetic or self-generated, explain how. If possible, please provide a link to the raw datasets.\n",
        "  * Statistics: include basic descriptive statistics of the dataset like size, cross validation split, label distribution, etc.\n",
        "  * Data process: how do you munipulate the data, e.g., change the class labels, split the dataset to train/valid/test, refining the dataset.\n",
        "  * Illustration: printing results, plotting figures for illustration.\n",
        "  * You can upload your raw dataset to Google Drive and mount this Colab to the same directory. If your raw dataset is too large, you can upload the processed dataset and have a code to load the processed dataset."
      ],
      "metadata": {
        "id": "2NbPHUTMbkD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source of the data: The data is extracted from the MIMIC III database [3]. This database contains de-identified health data associated with over 40,000 patients who stayed in intensive care units of the Beth Israel Deaconess Medical Center in Boston, MA, between 2001 and 2012.\n",
        "\n",
        "Statistics: The database includes 2,083,180 notes across 15 categories. The data covers more than 40,000 patients.\n",
        "\n",
        "Data process: I use the MicrobiologyEvents dataset and lable the tests with 80002 - Escherichia Coli as positive and other as negative. And find the notes of those patients in NoteEvents table. The clinical notes undergo punctuation removal and conversion to lowercase to standardize the text. Any names or private information relating to medical staff or patients are removed. Notes missing a 'charttime' are assigned a time of 23:59:59 on their respective 'chartdate'. The notes are tokenized using the WordPiece embedding technique and divided into segments of 128 tokens each."
      ],
      "metadata": {
        "id": "XzVUQS0CHry0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label(row):\n",
        "   if row['ORG_ITEMID'] == 80002:\n",
        "      return 1\n",
        "   return 0\n",
        "\n",
        "def main():\n",
        "    data1 = pd.read_csv('./MICROBIOLOGYEVENTS.csv')\n",
        "    data2 = pd.read_csv('./NOTEEVENTS.csv')\n",
        "\n",
        "    output1 = pd.merge(data1, data2,\n",
        "                   on='SUBJECT_ID',\n",
        "                   how='inner')\n",
        "\n",
        "    output1['Label'] = output1.apply(label, axis=1)\n",
        "    df1 = output1[['HADM_ID','ROW_ID','CHARTDATE','CHARTTIME','TEXT','Label']]\n",
        "    df1.to_csv('./newdata.csv', index=False)\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument(\"--original_data\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The input data file path.\"\n",
        "                             \" Should be the .tsv file (or other data file) for the task.\")\n",
        "    parser.add_argument(\"--output_dir\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The output directory where the processed data will be written.\")\n",
        "    parser.add_argument(\"--temp_dir\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The output directory where the intermediate processed data will be written.\")\n",
        "    parser.add_argument(\"--task_name\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The name of the task.\")\n",
        "    parser.add_argument(\"--log_path\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The log file path.\")\n",
        "    parser.add_argument(\"--id_num_neg\",\n",
        "                        default=None,\n",
        "                        type=int,\n",
        "                        required=True,\n",
        "                        help=\"The number of admission ids that we want to use for negative category.\")\n",
        "    parser.add_argument(\"--id_num_pos\",\n",
        "                        default=None,\n",
        "                        type=int,\n",
        "                        required=True,\n",
        "                        help=\"The number of admission ids that we want to use for positive category.\")\n",
        "    parser.add_argument(\"--random_seed\",\n",
        "                        default=1,\n",
        "                        type=int,\n",
        "                        required=True,\n",
        "                        help=\"The random_seed for train/val/test split.\")\n",
        "    parser.add_argument(\"--bert_model\",\n",
        "                        default=\"bert-base-uncased\",\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"Bert pre-trained model selected in the list: bert-base-uncased, \"\n",
        "                             \"bert-large-uncased, bert-base-cased, bert-base-multilingual, bert-base-chinese.\")\n",
        "\n",
        "    ## Other parameters\n",
        "    parser.add_argument(\"--Kfold\",\n",
        "                        default=None,\n",
        "                        type=int,\n",
        "                        required=False,\n",
        "                        help=\"The number of folds that we want ot use for cross validation. \"\n",
        "                             \"Default is not doing cross validation\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    RANDOM_SEED = args.random_seed\n",
        "    LOG_PATH = args.log_path\n",
        "    TEMP_DIR = args.temp_dir\n",
        "\n",
        "    if os.path.exists(TEMP_DIR) and os.listdir(TEMP_DIR):\n",
        "        raise ValueError(\"Temp Output directory ({}) already exists and is not empty.\".format(TEMP_DIR))\n",
        "    os.makedirs(TEMP_DIR, exist_ok=True)\n",
        "\n",
        "    if os.path.exists(args.output_dir) and os.listdir(args.output_dir):\n",
        "        raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(args.output_dir))\n",
        "    os.makedirs(args.output_dir, exist_ok=True)\n",
        "\n",
        "    original_df = pd.read_csv(args.original_data, header=None)\n",
        "    original_df.rename(columns={0: \"Adm_ID\",\n",
        "                                1: \"Note_ID\",\n",
        "                                2: \"chartdate\",\n",
        "                                3: \"charttime\",\n",
        "                                4: \"TEXT\",\n",
        "                                5: \"Label\"}, inplace=True)\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(args.bert_model, do_lower_case=True)\n",
        "\n",
        "    write_log((\"New Pre-processing Job Start! \\n\"\n",
        "               \"original_data: {}, output_dir: {}, temp_dir: {} \\n\"\n",
        "               \"task_name: {}, log_path: {}\\n\"\n",
        "               \"id_num_neg: {}, id_num_pos: {}\\n\"\n",
        "               \"random_seed: {}, bert_model: {}\").format(args.original_data, args.output_dir, args.temp_dir,\n",
        "                                                         args.task_name, args.log_path,\n",
        "                                                         args.id_num_neg, args.id_num_pos,\n",
        "                                                         args.random_seed, args.bert_model), LOG_PATH)\n",
        "\n",
        "    for i in range(int(np.ceil(len(original_df) / 10000))):\n",
        "        write_log(\"chunk {} tokenize start!\".format(i), LOG_PATH)\n",
        "        df_chunk = original_df.iloc[i * 10000:(i + 1) * 10000].copy()\n",
        "        df_processed_chunk = preprocessing(df_chunk, tokenizer)\n",
        "        df_processed_chunk = df_processed_chunk.astype({'Adm_ID': 'int64', 'Note_ID': 'int64', 'Label': 'int64'}, errors='ignore')\n",
        "        temp_file_dir = os.path.join(TEMP_DIR, 'Processed_{}.csv'.format(i))\n",
        "        df_processed_chunk.to_csv(temp_file_dir, index=False)\n",
        "\n",
        "    df = pd.DataFrame({'Adm_ID': [], 'Note_ID': [], 'TEXT': [], 'Input_ID': [],\n",
        "                       'Label': [], 'chartdate': [], 'charttime': []})\n",
        "    for i in range(int(np.ceil(len(original_df) / 10000))):\n",
        "        temp_file_dir = os.path.join(TEMP_DIR, 'Processed_{}.csv'.format(i))\n",
        "        df_chunk = pd.read_csv(temp_file_dir, header=0)\n",
        "        write_log(\"chunk {} has {} notes\".format(i, len(df_chunk)), LOG_PATH)\n",
        "        df_tmp = pd.concat([df, df_chunk], ignore_index=True)\n",
        "        df = df_tmp\n",
        "        del df_tmp\n",
        "\n",
        "\n",
        "    result = df.Label.value_counts()\n",
        "    write_log(\n",
        "        \"In the full dataset Positive Patients' Notes: {}, Negative Patients' Notes: {}\".format(result[1],\n",
        "                                                                                          result[0]),\n",
        "        LOG_PATH)\n",
        "\n",
        "    dead_ID = pd.Series(df[df.Label == 1].Adm_ID.unique())\n",
        "    not_dead_ID = pd.Series(df[df.Label == 0].Adm_ID.unique())\n",
        "    write_log(\"Total Positive Patients' ids: {}, Total Negative Patients' ids: {}\".format(len(dead_ID), len(not_dead_ID)), LOG_PATH)\n",
        "\n",
        "    not_dead_ID_use = not_dead_ID.sample(n=args.id_num_neg, random_state=RANDOM_SEED)\n",
        "    dead_ID_use = dead_ID.sample(n=args.id_num_pos, random_state=RANDOM_SEED)\n",
        "\n",
        "    if args.Kfold is None:\n",
        "        id_val_test_t = dead_ID_use.sample(frac=0.2, random_state=RANDOM_SEED)\n",
        "        id_val_test_f = not_dead_ID_use.sample(frac=0.2, random_state=RANDOM_SEED)\n",
        "\n",
        "        id_train_t = dead_ID_use.drop(id_val_test_t.index)\n",
        "        id_train_f = not_dead_ID_use.drop(id_val_test_f.index)\n",
        "\n",
        "        id_val_t = id_val_test_t.sample(frac=0.5, random_state=RANDOM_SEED)\n",
        "        id_test_t = id_val_test_t.drop(id_val_t.index)\n",
        "        id_val_f = id_val_test_f.sample(frac=0.5, random_state=RANDOM_SEED)\n",
        "        id_test_f = id_val_test_f.drop(id_val_f.index)\n",
        "\n",
        "        id_test = pd.concat([id_test_t, id_test_f])\n",
        "        test_id_label = pd.DataFrame(data=list(zip(id_test, [1] * len(id_test_t) + [0] * len(id_test_f))),\n",
        "                                     columns=['id', 'label'])\n",
        "\n",
        "        id_val = pd.concat([id_val_t, id_val_f])\n",
        "        val_id_label = pd.DataFrame(data=list(zip(id_val, [1] * len(id_val_t) + [0] * len(id_val_f))),\n",
        "                                    columns=['id', 'label'])\n",
        "\n",
        "        id_train = pd.concat([id_train_t, id_train_f])\n",
        "        train_id_label = pd.DataFrame(data=list(zip(id_train, [1] * len(id_train_t) + [0] * len(id_train_f))),\n",
        "                                      columns=['id', 'label'])\n",
        "\n",
        "        mortality_train = df[df.Adm_ID.isin(train_id_label.id)]\n",
        "        mortality_val = df[df.Adm_ID.isin(val_id_label.id)]\n",
        "        mortality_test = df[df.Adm_ID.isin(test_id_label.id)]\n",
        "        mortality_not_use = df[\n",
        "            (~df.Adm_ID.isin(train_id_label.id)) & (~df.Adm_ID.isin(val_id_label.id) & (~df.Adm_ID.isin(test_id_label.id)))]\n",
        "\n",
        "        train_result = mortality_train.Label.value_counts()\n",
        "\n",
        "        val_result = mortality_val.Label.value_counts()\n",
        "\n",
        "        test_result = mortality_test.Label.value_counts()\n",
        "\n",
        "        no_result = mortality_not_use.Label.value_counts()\n",
        "\n",
        "        mortality_train.to_csv(os.path.join(args.output_dir, 'train.csv'), index=False)\n",
        "        mortality_val.to_csv(os.path.join(args.output_dir, 'val.csv'), index=False)\n",
        "        mortality_test.to_csv(os.path.join(args.output_dir, 'test.csv'), index=False)\n",
        "        mortality_not_use.to_csv(os.path.join(args.output_dir, 'not_use.csv'), index=False)\n",
        "        df.to_csv(os.path.join(args.output_dir, 'full.csv'), index=False)\n",
        "\n",
        "        if len(no_result) == 2:\n",
        "            write_log((\"In the train dataset Positive Patients' Notes: {}, Negative Patients' Notes: {}\\n\"\n",
        "                       \"In the validation dataset Positive Patients' Notes: {}, Negative Patients' Notes: {}\\n\"\n",
        "                       \"In the test dataset Positive Patients' Notes: {}, Negative Patients' Notes: {}\\n\"\n",
        "                       \"In the not use dataset Positive Patients' Notes: {}, Negative Patients' Notes: {}\").format(\n",
        "                train_result[1],\n",
        "                train_result[0],\n",
        "                val_result[1],\n",
        "                val_result[0],\n",
        "                test_result[1],\n",
        "                test_result[0],\n",
        "                no_result[1],\n",
        "                no_result[0]),\n",
        "                LOG_PATH)\n",
        "        else:\n",
        "            try:\n",
        "                write_log((\"In the train dataset Positive Patients' Notes: {}, Negative  Patients' Notes: {}\\n\"\n",
        "                           \"In the validation dataset Positive Patients' Notes: {}, Negative Patients' Notes: {}\\n\"\n",
        "                           \"In the test dataset Positive Patients' Notes: {}, Negative Patients' Notes: {}\\n\"\n",
        "                           \"In the not use dataset Negative Patients' Notes: {}\").format(train_result[1],\n",
        "                                                                                          train_result[0],\n",
        "                                                                                          val_result[1],\n",
        "                                                                                          val_result[0],\n",
        "                                                                                          test_result[1],\n",
        "                                                                                          test_result[0],\n",
        "                                                                                          no_result[0]),\n",
        "                          LOG_PATH)\n",
        "            except KeyError:\n",
        "                write_log((\"In the train dataset Positive Patients' Notes: {}, Negative  Patients' Notes: {}\\n\"\n",
        "                           \"In the validation dataset Positive Patients' Notes: {}, Negative Patients' Notes: {}\\n\"\n",
        "                           \"In the test dataset Positive Patients' Notes: {}, Negative Patients' Notes: {}\\n\"\n",
        "                           \"In the not use dataset Positive Patients' Notes: {}\").format(train_result[1],\n",
        "                                                                                          train_result[0],\n",
        "                                                                                          val_result[1],\n",
        "                                                                                          val_result[0],\n",
        "                                                                                          test_result[1],\n",
        "                                                                                          test_result[0],\n",
        "                                                                                          no_result[1]),\n",
        "                          LOG_PATH)\n",
        "\n",
        "        write_log(\"Data saved in the {}\".format(args.output_dir), LOG_PATH)\n",
        "    else:\n",
        "        folds_t = KFold(args.Kfold, False, RANDOM_SEED)\n",
        "        folds_f = KFold(args.Kfold, False, RANDOM_SEED)\n",
        "        dead_ID_use.reset_index(inplace=True, drop=True)\n",
        "        not_dead_ID_use.reset_index(inplace=True, drop=True)\n",
        "        for num, ((train_t, test_t), (train_f, test_f)) in enumerate(zip(folds_t.split(dead_ID_use),\n",
        "                                                                         folds_f.split(not_dead_ID_use))):\n",
        "            id_train_t = dead_ID_use[train_t]\n",
        "            id_val_test_t = dead_ID_use[test_t]\n",
        "            id_train_f = not_dead_ID_use[train_f]\n",
        "            id_val_test_f = not_dead_ID_use[test_f]\n",
        "            id_val_t = id_val_test_t.sample(frac=0.5, random_state=RANDOM_SEED)\n",
        "            id_test_t = id_val_test_t.drop(id_val_t.index)\n",
        "            id_val_f = id_val_test_f.sample(frac=0.5, random_state=RANDOM_SEED)\n",
        "            id_test_f = id_val_test_f.drop(id_val_f.index)\n",
        "\n",
        "            id_test = pd.concat([id_test_t, id_test_f])\n",
        "            test_id_label = pd.DataFrame(data=list(zip(id_test, [1] * len(id_test_t) + [0] * len(id_test_f))),\n",
        "                                         columns=['id', 'label'])\n",
        "\n",
        "            id_val = pd.concat([id_val_t, id_val_f])\n",
        "            val_id_label = pd.DataFrame(data=list(zip(id_val, [1] * len(id_val_t) + [0] * len(id_val_f))),\n",
        "                                        columns=['id', 'label'])\n",
        "\n",
        "            id_train = pd.concat([id_train_t, id_train_f])\n",
        "            train_id_label = pd.DataFrame(data=list(zip(id_train, [1] * len(id_train_t) + [0] * len(id_train_f))),\n",
        "                                          columns=['id', 'label'])\n",
        "\n",
        "            mortality_train = df[df.Adm_ID.isin(train_id_label.id)]\n",
        "            mortality_val = df[df.Adm_ID.isin(val_id_label.id)]\n",
        "            mortality_test = df[df.Adm_ID.isin(test_id_label.id)]\n",
        "            mortality_not_use = df[\n",
        "                (~df.Adm_ID.isin(train_id_label.id)) & (\n",
        "                            ~df.Adm_ID.isin(val_id_label.id) & (~df.Adm_ID.isin(test_id_label.id)))]\n",
        "\n",
        "            train_result = mortality_train.Label.value_counts()\n",
        "\n",
        "            val_result = mortality_val.Label.value_counts()\n",
        "\n",
        "            test_result = mortality_test.Label.value_counts()\n",
        "\n",
        "            no_result = mortality_not_use.Label.value_counts()\n",
        "\n",
        "            os.makedirs(os.path.join(args.output_dir, str(num)))\n",
        "            mortality_train.to_csv(os.path.join(args.output_dir, str(num), 'train.csv'), index=False)\n",
        "            mortality_val.to_csv(os.path.join(args.output_dir, str(num), 'val.csv'), index=False)\n",
        "            mortality_test.to_csv(os.path.join(args.output_dir, str(num), 'test.csv'), index=False)\n",
        "            mortality_not_use.to_csv(os.path.join(args.output_dir, str(num), 'not_use.csv'), index=False)\n",
        "            df.to_csv(os.path.join(args.output_dir, str(num), 'full.csv'), index=False)\n",
        "\n",
        "            if len(no_result) == 2:\n",
        "                write_log((\"In the {}th split of {} folds\\n\"\n",
        "                           \"In the train dataset Positive Patients' Notes: {}, Negative Patients' Notes: {}\\n\"\n",
        "                           \"In the validation dataset Positive Patients' Notes: {}, Negative Patients' Notes: {}\\n\"\n",
        "                           \"In the test dataset Positive Patients' Notes: {}, Negative Patients' Notes: {}\\n\"\n",
        "                           \"In the not use dataset Positive Patients' Notes: {}, Negative Patients' Notes: {}\").format(\n",
        "                    num,\n",
        "                    args.Kfold,\n",
        "                    train_result[1],\n",
        "                    train_result[0],\n",
        "                    val_result[1],\n",
        "                    val_result[0],\n",
        "                    test_result[1],\n",
        "                    test_result[0],\n",
        "                    no_result[1],\n",
        "                    no_result[0]),\n",
        "                    LOG_PATH)\n",
        "            else:\n",
        "                try:\n",
        "                    write_log((\"In the {}th split of {} folds\\n\"\n",
        "                               \"In the train dataset Positive Patients' Notes: {}, Negative  Patients' Notes: {}\\n\"\n",
        "                               \"In the validation dataset Positive Patients' Notes: {}, Negative Patients' Notes: {}\\n\"\n",
        "                               \"In the test dataset Positive Patients' Notes: {}, Negative Patients' Notes: {}\\n\"\n",
        "                               \"In the not use dataset Negative Patients' Notes: {}\").format(num,\n",
        "                                                                                              args.Kfold,\n",
        "                                                                                              train_result[1],\n",
        "                                                                                              train_result[0],\n",
        "                                                                                              val_result[1],\n",
        "                                                                                              val_result[0],\n",
        "                                                                                              test_result[1],\n",
        "                                                                                              test_result[0],\n",
        "                                                                                              no_result[0]),\n",
        "                              LOG_PATH)\n",
        "                except KeyError:\n",
        "                    write_log((\"In the {}th split of {} folds\\n\"\n",
        "                               \"In the train dataset Positive Patients' Notes: {}, Negative  Patients' Notes: {}\\n\"\n",
        "                               \"In the validation dataset Positive Patients' Notes: {}, Negative Patients' Notes: {}\\n\"\n",
        "                               \"In the test dataset Positive Patients' Notes: {}, Negative Patients' Notes: {}\\n\"\n",
        "                               \"In the not use dataset Positive Patients' Notes: {}\").format(num,\n",
        "                                                                                             args.Kfold,\n",
        "                                                                                             train_result[1],\n",
        "                                                                                             train_result[0],\n",
        "                                                                                             val_result[1],\n",
        "                                                                                             val_result[0],\n",
        "                                                                                             test_result[1],\n",
        "                                                                                             test_result[0],\n",
        "                                                                                             no_result[1]),\n",
        "                              LOG_PATH)\n",
        "\n",
        "            write_log(\"Data saved in the {}\".format(os.path.join(args.output_dir, str(num))), LOG_PATH)\n"
      ],
      "metadata": {
        "id": "ghBxFc7AaB4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##   Model\n",
        "The model includes the model definitation which usually is a class, model training, and other necessary parts.\n",
        "  * Model architecture: layer number/size/type, activation function, etc\n",
        "  * Training objectives: loss function, optimizer, weight of each loss term, etc\n",
        "  * Others: whether the model is pretrained, Monte Carlo simulation for uncertainty analysis, etc\n",
        "  * The code of model should have classes of the model, functions of model training, model validation, etc.\n",
        "  * If your model training is done outside of this notebook, please upload the trained model here and develop a function to load and test it."
      ],
      "metadata": {
        "id": "3muyDPFPbozY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Base model using is BERT [2]."
      ],
      "metadata": {
        "id": "KRH_bLn_agc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_patient_score(df, c):\n",
        "    df_sort = df.sort_values(by=['Adm_ID'])\n",
        "    # score\n",
        "    temp = (df_sort.groupby(['Adm_ID'])['logits'].agg(max) + df_sort.groupby(['Adm_ID'])['logits'].agg(\n",
        "        sum) / c) / (1 + df_sort.groupby(['Adm_ID'])['logits'].agg(len) / c)\n",
        "    x = df_sort.groupby(['Adm_ID'])['label'].agg(np.min).values\n",
        "    predictions = (temp.values >= 0.5).astype(np.int)\n",
        "    ids = df_sort['Adm_ID'].unique()\n",
        "    df_out = pd.DataFrame({'logits': temp.values, 'pred_label': predictions, 'label': x, 'Adm_ID': ids})\n",
        "    return df_out\n",
        "\n",
        "\n",
        "def test_func(sublist):\n",
        "    if sublist.shape is ():\n",
        "        return [sublist.tolist()]\n",
        "    else:\n",
        "        return sublist\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    ## Required parameters\n",
        "    parser.add_argument(\"--data_dir\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\")\n",
        "\n",
        "    parser.add_argument(\"--train_data\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The input training data file name.\"\n",
        "                             \" Should be the .tsv file (or other data file) for the task.\")\n",
        "\n",
        "    parser.add_argument(\"--val_data\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The input validation data file name.\"\n",
        "                             \" Should be the .tsv file (or other data file) for the task.\")\n",
        "\n",
        "    parser.add_argument(\"--test_data\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The input test data file name.\"\n",
        "                             \" Should be the .tsv file (or other data file) for the task.\")\n",
        "\n",
        "    parser.add_argument(\"--log_path\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The log file path.\")\n",
        "\n",
        "    parser.add_argument(\"--output_dir\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The output directory where the model checkpoints will be written.\")\n",
        "\n",
        "    parser.add_argument(\"--save_model\",\n",
        "                        default=False,\n",
        "                        action='store_true',\n",
        "                        help=\"Whether to save the model.\")\n",
        "\n",
        "    parser.add_argument(\"--bert_model\",\n",
        "                        default=\"bert-base-uncased\",\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"Bert pre-trained model selected in the list: bert-base-uncased, \"\n",
        "                             \"bert-large-uncased, bert-base-cased, bert-base-multilingual, bert-base-chinese.\")\n",
        "\n",
        "    parser.add_argument(\"--embed_mode\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The embedding type selected in the list: all, note, chunk, no.\")\n",
        "\n",
        "    parser.add_argument(\"--c\",\n",
        "                        type=float,\n",
        "                        required=True,\n",
        "                        help=\"The parameter c for scaled adjusted mean method\")\n",
        "\n",
        "    parser.add_argument(\"--task_name\",\n",
        "                        default=\"BERT_mortality_am\",\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The name of the task.\")\n",
        "\n",
        "    ## Other parameters\n",
        "    parser.add_argument(\"--max_seq_length\",\n",
        "                        default=128,\n",
        "                        type=int,\n",
        "                        help=\"The maximum total input sequence length after WordPiece tokenization. \\n\"\n",
        "                             \"Sequences longer than this will be truncated, and sequences shorter \\n\"\n",
        "                             \"than this will be padded.\")\n",
        "    parser.add_argument(\"--max_chunk_num\",\n",
        "                        default=64,\n",
        "                        type=int,\n",
        "                        help=\"The maximum total input chunk numbers after WordPiece tokenization.\")\n",
        "    parser.add_argument(\"--train_batch_size\",\n",
        "                        default=1,\n",
        "                        type=int,\n",
        "                        help=\"Total batch size for training.\")\n",
        "    parser.add_argument(\"--eval_batch_size\",\n",
        "                        default=1,\n",
        "                        type=int,\n",
        "                        help=\"Total batch size for eval.\")\n",
        "    parser.add_argument(\"--learning_rate\",\n",
        "                        default=2e-5,\n",
        "                        type=float,\n",
        "                        help=\"The initial learning rate for Adam.\")\n",
        "    parser.add_argument(\"--warmup_proportion\",\n",
        "                        default=0.0,\n",
        "                        type=float,\n",
        "                        help=\"Proportion of training to perform linear learning rate warmup for. \"\n",
        "                             \"E.g., 0.1 = 10%% of training.\")\n",
        "    parser.add_argument(\"--num_train_epochs\",\n",
        "                        default=3,\n",
        "                        type=int,\n",
        "                        help=\"Total number of training epochs to perform.\")\n",
        "    parser.add_argument('--seed',\n",
        "                        type=int,\n",
        "                        default=42,\n",
        "                        help=\"random seed for initialization\")\n",
        "    parser.add_argument('--gradient_accumulation_steps',\n",
        "                        type=int,\n",
        "                        default=1,\n",
        "                        help=\"Number of updates steps to accumualte before performing a backward/update pass.\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.save_model:\n",
        "        raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(args.output_dir))\n",
        "    os.makedirs(args.output_dir, exist_ok=True)\n",
        "\n",
        "    LOG_PATH = args.log_path\n",
        "    MAX_LEN = args.max_seq_length\n",
        "\n",
        "    config = DotMap()\n",
        "    config.hidden_dropout_prob = 0.1\n",
        "    config.layer_norm_eps = 1e-12\n",
        "    config.initializer_range = 0.02\n",
        "    config.max_note_position_embedding = 1000\n",
        "    config.max_chunk_position_embedding = 1000\n",
        "    config.embed_mode = args.embed_mode\n",
        "    config.layer_norm_eps = 1e-12\n",
        "    config.hidden_size = 768\n",
        "\n",
        "    config.task_name = args.task_name\n",
        "\n",
        "    write_log((\"New Job Start! \\n\"\n",
        "               \"Data directory: {}, Directory Code: {}, Save Model: {}\\n\"\n",
        "               \"Output_dir: {}, Task Name: {}, embed_mode: {}\\n\"\n",
        "               \"max_seq_length: {},  max_chunk_num: {}\\n\"\n",
        "               \"train_batch_size: {}, eval_batch_size: {}\\n\"\n",
        "               \"learning_rate: {}, warmup_proportion: {}\\n\"\n",
        "               \"num_train_epochs: {}, seed: {}, gradient_accumulation_steps: {}\").format(args.data_dir,\n",
        "                                                                                         args.data_dir.split('_')[-1],\n",
        "                                                                                         args.save_model,\n",
        "                                                                                         args.output_dir,\n",
        "                                                                                         config.task_name,\n",
        "                                                                                         config.embed_mode,\n",
        "                                                                                         args.max_seq_length,\n",
        "                                                                                         args.max_chunk_num,\n",
        "                                                                                         args.train_batch_size,\n",
        "                                                                                         args.eval_batch_size,\n",
        "                                                                                         args.learning_rate,\n",
        "                                                                                         args.warmup_proportion,\n",
        "                                                                                         args.num_train_epochs,\n",
        "                                                                                         args.seed,\n",
        "                                                                                         args.gradient_accumulation_steps),\n",
        "              LOG_PATH)\n",
        "\n",
        "    content = \"config setting: \\n\"\n",
        "    for k, v in config.items():\n",
        "        content += \"{}: {} \\n\".format(k, v)\n",
        "    write_log(content, LOG_PATH)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "    write_log(\"Number of GPU is {}\".format(n_gpu), LOG_PATH)\n",
        "    for i in range(n_gpu):\n",
        "        write_log((\"Device Name: {},\"\n",
        "                   \"Device Capability: {}\").format(torch.cuda.get_device_name(i),\n",
        "                                                   torch.cuda.get_device_capability(i)), LOG_PATH)\n",
        "\n",
        "    train_file_path = os.path.join(args.data_dir, args.train_data)\n",
        "    val_file_path = os.path.join(args.data_dir, args.val_data)\n",
        "    test_file_path = os.path.join(args.data_dir, args.test_data)\n",
        "    train_df = pd.read_csv(train_file_path)\n",
        "    val_df = pd.read_csv(val_file_path)\n",
        "    test_df = pd.read_csv(test_file_path)\n",
        "\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(args.bert_model, do_lower_case=True)\n",
        "\n",
        "    write_log(\"Tokenize Start!\", LOG_PATH)\n",
        "    train_labels, train_inputs, train_masks, train_note_ids = Tokenize_with_note_id(train_df, MAX_LEN, tokenizer)\n",
        "    validation_labels, validation_inputs, validation_masks, validation_note_ids = Tokenize_with_note_id(val_df, MAX_LEN,\n",
        "                                                                                                        tokenizer)\n",
        "    test_labels, test_inputs, test_masks, test_note_ids = Tokenize_with_note_id(test_df, MAX_LEN, tokenizer)\n",
        "    write_log(\"Tokenize Finished!\", LOG_PATH)\n",
        "    train_inputs = torch.tensor(train_inputs)\n",
        "    validation_inputs = torch.tensor(validation_inputs)\n",
        "    test_inputs = torch.tensor(test_inputs)\n",
        "    train_labels = torch.tensor(train_labels)\n",
        "    validation_labels = torch.tensor(validation_labels)\n",
        "    test_labels = torch.tensor(test_labels)\n",
        "    train_masks = torch.tensor(train_masks)\n",
        "    validation_masks = torch.tensor(validation_masks)\n",
        "    test_masks = torch.tensor(test_masks)\n",
        "    write_log((\"train dataset size is %d,\\n\"\n",
        "               \"validation dataset size is %d,\\n\"\n",
        "               \"test dataset size is %d\") % (len(train_inputs), len(validation_inputs), len(test_inputs)), LOG_PATH)\n",
        "\n",
        "    (train_labels, train_inputs,\n",
        "     train_masks, train_ids,\n",
        "     train_note_ids, train_chunk_ids) = concat_by_id_list_with_note_chunk_id(train_df, train_labels,\n",
        "                                                                             train_inputs, train_masks,\n",
        "                                                                             train_note_ids, MAX_LEN)\n",
        "    (validation_labels, validation_inputs,\n",
        "     validation_masks, validation_ids,\n",
        "     validation_note_ids, validation_chunk_ids) = concat_by_id_list_with_note_chunk_id(val_df, validation_labels,\n",
        "                                                                                       validation_inputs,\n",
        "                                                                                       validation_masks,\n",
        "                                                                                       validation_note_ids, MAX_LEN)\n",
        "    (test_labels, test_inputs,\n",
        "     test_masks, test_ids,\n",
        "     test_note_ids, test_chunk_ids) = concat_by_id_list_with_note_chunk_id(test_df, test_labels,\n",
        "                                                                           test_inputs, test_masks,\n",
        "                                                                           test_note_ids, MAX_LEN)\n",
        "\n",
        "    model = BertForSequenceClassification.from_pretrained(args.bert_model, num_labels=2)\n",
        "    model.to(device)\n",
        "    if n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "    num_train_steps = int(\n",
        "        len(train_df) / args.train_batch_size / args.gradient_accumulation_steps * args.num_train_epochs)\n",
        "\n",
        "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                         lr=args.learning_rate,\n",
        "                         warmup=args.warmup_proportion,\n",
        "                         t_total=num_train_steps)\n",
        "\n",
        "    m = torch.nn.Softmax(dim=1)\n",
        "\n",
        "    start = time.time()\n",
        "    # Store our loss and accuracy for plotting\n",
        "    train_loss_set = []\n",
        "\n",
        "    # Number of training epochs (authors recommend between 2 and 4)\n",
        "    epochs = args.num_train_epochs\n",
        "\n",
        "    train_batch_generator = mask_batch_generator(args.max_chunk_num, train_inputs, train_labels, train_masks)\n",
        "    validation_batch_generator = mask_batch_generator(args.max_chunk_num, validation_inputs, validation_labels,\n",
        "                                                      validation_masks)\n",
        "\n",
        "    write_log(\"Training start!\", LOG_PATH)\n",
        "    # trange is a tqdm wrapper around the normal python range\n",
        "    with torch.autograd.set_detect_anomaly(True):\n",
        "        for epoch in trange(epochs, desc=\"Epoch\"):\n",
        "            # Training\n",
        "\n",
        "            # Set our model to training mode (as opposed to evaluation mode)\n",
        "            model.train()\n",
        "\n",
        "            # Tracking variables\n",
        "            tr_loss = 0\n",
        "            nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "            # Train the data for one epoch\n",
        "            tr_ids_num = len(train_ids)\n",
        "            tr_batch_loss = []\n",
        "            for step in range(tr_ids_num):\n",
        "                b_input_ids, b_labels, b_input_mask = next(train_batch_generator)\n",
        "                b_input_ids = b_input_ids.to(device)\n",
        "                b_input_mask = b_input_mask.to(device)\n",
        "                b_labels = b_labels.repeat(b_input_ids.shape[0]).to(device)\n",
        "                # Forward pass\n",
        "                outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "                loss, logits = outputs[:2]\n",
        "                if n_gpu > 1:\n",
        "                    loss = loss.mean()  # mean() to average on multi-gpu.\n",
        "                train_loss_set.append(loss.item())\n",
        "                # Backward pass\n",
        "                loss.backward()\n",
        "                # Update parameters and take a step using the computed gradient\n",
        "                if (step + 1) % args.train_batch_size == 0:\n",
        "                    optimizer.step()\n",
        "                    optimizer.zero_grad()\n",
        "                    train_loss_set.append(np.mean(tr_batch_loss))\n",
        "                    tr_batch_loss = []\n",
        "\n",
        "                # Update tracking variables\n",
        "                tr_loss += loss.item()\n",
        "                nb_tr_examples += b_input_ids.size(0)\n",
        "                nb_tr_steps += 1\n",
        "\n",
        "\n",
        "            write_log(\"Train loss: {}\".format(tr_loss / nb_tr_steps), LOG_PATH)\n",
        "\n",
        "            # Validation\n",
        "\n",
        "            # Put model in evaluation mode to evaluate loss on the validation set\n",
        "            model.eval()\n",
        "\n",
        "            # Tracking variables\n",
        "            eval_loss, eval_accuracy = 0, 0\n",
        "            nb_eval_steps, nb_eval_examples = 0, 0\n",
        "            # Evaluate data for one epoch\n",
        "            ev_ids_num = len(validation_ids)\n",
        "            for step in range(ev_ids_num):\n",
        "                with torch.no_grad():\n",
        "                    b_input_ids, b_labels, b_input_mask = next(validation_batch_generator)\n",
        "                    b_input_ids = b_input_ids.to(device)\n",
        "                    b_input_mask = b_input_mask.to(device)\n",
        "                    b_labels = b_labels.repeat(b_input_ids.shape[0])\n",
        "                    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "                    # Move logits and labels to CPU\n",
        "                    logits = outputs[-1]\n",
        "                    logits = m(logits).detach().cpu().numpy()[:, 1]\n",
        "                    label_ids = b_labels.numpy()\n",
        "\n",
        "                    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "                    eval_accuracy += tmp_eval_accuracy\n",
        "                    nb_eval_steps += 1\n",
        "\n",
        "            write_log(\"Validation Accuracy: {}\".format(eval_accuracy / nb_eval_steps), LOG_PATH)\n",
        "            output_checkpoints_path = os.path.join(args.output_dir,\n",
        "                                                   \"bert_fine_tuned_with_note_checkpoint_%d.pt\" % epoch)\n",
        "            if args.save_model:\n",
        "                if n_gpu > 1:\n",
        "                    torch.save({\n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': model.module.state_dict(),\n",
        "                        'optimizer_state_dict': optimizer.state_dict(),\n",
        "                        'loss': loss,\n",
        "                    },\n",
        "                        output_checkpoints_path)\n",
        "\n",
        "                else:\n",
        "                    torch.save({\n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                        'optimizer_state_dict': optimizer.state_dict(),\n",
        "                        'loss': loss,\n",
        "                    },\n",
        "                        output_checkpoints_path)\n",
        "    end = time.time()\n",
        "\n",
        "    write_log(\"total training time is: {}s\".format(end - start), LOG_PATH)\n",
        "\n",
        "    fig1 = plt.figure(figsize=(15, 8))\n",
        "    plt.title(\"Training loss\")\n",
        "    plt.xlabel(\"Chunk Batch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.plot(train_loss_set)\n",
        "    if args.save_model:\n",
        "        output_fig_path = os.path.join(args.output_dir, \"bert_fine_tuned_with_note_training_loss.png\")\n",
        "        plt.savefig(output_fig_path, dpi=fig1.dpi)\n",
        "        output_model_state_dict_path = os.path.join(args.output_dir,\n",
        "                                                    \"bert_fine_tuned_with_note_state_dict.pt\")\n",
        "        if n_gpu > 1:\n",
        "            torch.save(model.module.state_dict(), output_model_state_dict_path)\n",
        "        else:\n",
        "            torch.save(model.state_dict(), output_model_state_dict_path)\n",
        "        write_log(\"Model saved!\", LOG_PATH)\n",
        "    else:\n",
        "        output_fig_path = os.path.join(args.output_dir,\n",
        "                                       \"bert_fine_tuned_with_note_training_loss_{}_{}.png\".format(\n",
        "                                           args.seed,\n",
        "                                           args.data_dir.split(\n",
        "                                               '_')[-1]))\n",
        "        plt.savefig(output_fig_path, dpi=fig1.dpi)\n",
        "        write_log(\"Model not saved as required\", LOG_PATH)\n",
        "\n",
        "    # Prediction on test set\n",
        "\n",
        "    # Put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    predictions, true_labels, test_adm_ids = [], [], []\n",
        "\n",
        "    # Predict\n",
        "    te_ids_num = len(test_ids)\n",
        "    for step in range(te_ids_num):\n",
        "        b_input_ids = test_inputs[step][-args.max_chunk_num:, :].to(device)\n",
        "        b_input_mask = test_masks[step][-args.max_chunk_num:, :].to(device)\n",
        "        b_labels = test_labels[step].repeat(b_input_ids.shape[0])\n",
        "        # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n",
        "        with torch.no_grad():\n",
        "            # Forward pass, calculate logit predictions\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = outputs[-1]\n",
        "        logits = m(logits).detach().cpu().numpy()[:, 1]\n",
        "        label_ids = b_labels.numpy()\n",
        "        adm_ids = test_ids[step].repeat(b_input_ids.shape[0])\n",
        "\n",
        "        # Store predictions and true labels\n",
        "        predictions.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "        test_adm_ids.append(adm_ids)\n",
        "\n",
        "    try:\n",
        "        flat_logits = [item for sublist in predictions for item in sublist]\n",
        "    except TypeError:\n",
        "        flat_logits = [item for sublist in predictions for item in test_func(sublist)]\n",
        "    flat_predictions = (np.array(flat_logits) >= 0.5).astype(np.int)\n",
        "    try:\n",
        "        flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "    except TypeError:\n",
        "        flat_true_labels = [item for sublist in true_labels for item in test_func(sublist)]\n",
        "    try:\n",
        "        flat_adm_ids = [item for sublist in test_adm_ids for item in sublist]\n",
        "    except TypeError:\n",
        "        flat_adm_ids = [item for sublist in test_adm_ids for item in test_func(sublist)]\n",
        "\n",
        "    output_chunk_df = pd.DataFrame({'logits': flat_logits,\n",
        "                                    'pred_label': flat_predictions,\n",
        "                                    'label': flat_true_labels,\n",
        "                                    'Adm_ID': flat_adm_ids})\n",
        "\n",
        "    if args.save_model:\n",
        "        output_chunk_df.to_csv(os.path.join(args.output_dir, 'test_chunk_predictions.csv'), index=False)\n",
        "    else:\n",
        "        output_chunk_df.to_csv(os.path.join(args.output_dir,\n",
        "                                            'test_chunk_predictions_{}_{}.csv'.format(args.seed,\n",
        "                                                                                      args.data_dir.split('_')[-1])),\n",
        "                               index=False)\n",
        "\n",
        "    output_df = get_patient_score(output_chunk_df, args.c)\n",
        "    if args.save_model:\n",
        "        output_df.to_csv(os.path.join(args.output_dir, 'test_predictions.csv'), index=False)\n",
        "    else:\n",
        "        output_df.to_csv(os.path.join(args.output_dir,\n",
        "                                      'test_predictions_{}_{}.csv'.format(args.seed,\n",
        "                                                                          args.data_dir.split('_')[-1])),\n",
        "                         index=False)\n",
        "    write_performance(output_df['label'].values, output_df['pred_label'].values,\n",
        "                      output_df['logits'].values, config, args)\n"
      ],
      "metadata": {
        "id": "Eet6xK1Eacbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model without time info to test H2."
      ],
      "metadata": {
        "id": "JV9iKvypbL_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    ## Required parameters\n",
        "    parser.add_argument(\"--data_dir\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\")\n",
        "\n",
        "    parser.add_argument(\"--train_data\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The input training data file name.\"\n",
        "                             \" Should be the .tsv file (or other data file) for the task.\")\n",
        "\n",
        "    parser.add_argument(\"--val_data\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The input validation data file name.\"\n",
        "                             \" Should be the .tsv file (or other data file) for the task.\")\n",
        "\n",
        "    parser.add_argument(\"--test_data\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The input test data file name.\"\n",
        "                             \" Should be the .tsv file (or other data file) for the task.\")\n",
        "\n",
        "    parser.add_argument(\"--log_path\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The log file path.\")\n",
        "\n",
        "    parser.add_argument(\"--output_dir\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The output directory where the model checkpoints will be written.\")\n",
        "\n",
        "    parser.add_argument(\"--save_model\",\n",
        "                        default=False,\n",
        "                        action='store_true',\n",
        "                        help=\"Whether to save the model.\")\n",
        "\n",
        "    parser.add_argument(\"--bert_model\",\n",
        "                        default=\"bert-base-uncased\",\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"Bert pre-trained model selected in the list: bert-base-uncased, \"\n",
        "                             \"bert-large-uncased, bert-base-cased, bert-base-multilingual, bert-base-chinese.\")\n",
        "\n",
        "    parser.add_argument(\"--embed_mode\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The embedding type selected in the list: all, note, chunk, no.\")\n",
        "\n",
        "    parser.add_argument(\"--task_name\",\n",
        "                        default=\"Patient_Transformer_with_ClBERT_mortality\",\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The name of the task.\")\n",
        "\n",
        "\n",
        "    ## Other parameters\n",
        "    parser.add_argument(\"--max_seq_length\",\n",
        "                        default=128,\n",
        "                        type=int,\n",
        "                        help=\"The maximum total input sequence length after WordPiece tokenization. \\n\"\n",
        "                             \"Sequences longer than this will be truncated, and sequences shorter \\n\"\n",
        "                             \"than this will be padded.\")\n",
        "    parser.add_argument(\"--max_chunk_num\",\n",
        "                        default=64,\n",
        "                        type=int,\n",
        "                        help=\"The maximum total input chunk numbers after WordPiece tokenization.\")\n",
        "    parser.add_argument(\"--train_batch_size\",\n",
        "                        default=1,\n",
        "                        type=int,\n",
        "                        help=\"Total batch size for training.\")\n",
        "    parser.add_argument(\"--eval_batch_size\",\n",
        "                        default=1,\n",
        "                        type=int,\n",
        "                        help=\"Total batch size for eval.\")\n",
        "    parser.add_argument(\"--learning_rate\",\n",
        "                        default=2e-5,\n",
        "                        type=float,\n",
        "                        help=\"The initial learning rate for Adam.\")\n",
        "    parser.add_argument(\"--warmup_proportion\",\n",
        "                        default=0.0,\n",
        "                        type=float,\n",
        "                        help=\"Proportion of training to perform linear learning rate warmup for. \"\n",
        "                             \"E.g., 0.1 = 10%% of training.\")\n",
        "    parser.add_argument(\"--num_train_epochs\",\n",
        "                        default=3,\n",
        "                        type=int,\n",
        "                        help=\"Total number of training epochs to perform.\")\n",
        "    parser.add_argument('--seed',\n",
        "                        type=int,\n",
        "                        default=42,\n",
        "                        help=\"random seed for initialization\")\n",
        "    parser.add_argument('--gradient_accumulation_steps',\n",
        "                        type=int,\n",
        "                        default=1,\n",
        "                        help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
        "    parser.add_argument('--num_hidden_layers',\n",
        "                        type=int,\n",
        "                        default=2,\n",
        "                        help=\"Number of hidden layers in the patient model.\")\n",
        "    parser.add_argument('--num_attention_heads',\n",
        "                        type=int,\n",
        "                        default=12,\n",
        "                        help=\"Number of attention heads in the patient model.\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.save_model:\n",
        "        raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(args.output_dir))\n",
        "    os.makedirs(args.output_dir, exist_ok=True)\n",
        "\n",
        "    LOG_PATH = args.log_path\n",
        "    MAX_LEN = args.max_seq_length\n",
        "\n",
        "    config = DotMap()\n",
        "    config.hidden_dropout_prob = 0.1\n",
        "    config.attention_probs_dropout_prob = 0.1\n",
        "    config.initializer_range = 0.02\n",
        "    config.num_hidden_layers = args.num_hidden_layers\n",
        "    config.num_attention_heads = args.num_attention_heads\n",
        "    config.max_note_position_embedding = 1000\n",
        "    config.max_chunk_position_embedding = 1000\n",
        "    config.embed_mode = args.embed_mode\n",
        "    config.layer_norm_eps = 1e-12\n",
        "    config.hidden_act = \"gelu\"\n",
        "    config.hidden_size = 768\n",
        "    config.intermediate_size = 3072\n",
        "\n",
        "    config.task_name = args.task_name\n",
        "\n",
        "    write_log((\"New Job Start! \\n\"\n",
        "               \"Data directory: {}, Directory Code: {}, Save Model: {}\\n\"\n",
        "               \"Output_dir: {}, Task Name: {}, embed_mode: {}\\n\"\n",
        "               \"max_seq_length: {},  max_chunk_num: {}\\n\"\n",
        "               \"train_batch_size: {}, eval_batch_size: {}\\n\"\n",
        "               \"learning_rate: {}, warmup_proportion: {} \\n\"\n",
        "               \"num_train_epochs: {}, seed: {}, gradient_accumulation_steps: {} \\n\"\n",
        "               \"Patient Model's num_hidden_layers: {}, num_attention_heads: {}\").format(args.data_dir,\n",
        "                                                                                        args.data_dir.split('_')[-1],\n",
        "                                                                                        args.save_model,\n",
        "                                                                                        args.output_dir,\n",
        "                                                                                        config.task_name,\n",
        "                                                                                        config.embed_mode,\n",
        "                                                                                        args.max_seq_length,\n",
        "                                                                                        args.max_chunk_num,\n",
        "                                                                                        args.train_batch_size,\n",
        "                                                                                        args.eval_batch_size,\n",
        "                                                                                        args.learning_rate,\n",
        "                                                                                        args.warmup_proportion,\n",
        "                                                                                        args.num_train_epochs,\n",
        "                                                                                        args.seed,\n",
        "                                                                                        args.gradient_accumulation_steps,\n",
        "                                                                                        config.num_hidden_layers,\n",
        "                                                                                        config.num_attention_heads),\n",
        "              LOG_PATH)\n",
        "\n",
        "    content = \"config setting: \\n\"\n",
        "    for k, v in config.items():\n",
        "        content += \"{}: {} \\n\".format(k, v)\n",
        "    write_log(content, LOG_PATH)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "    write_log(\"Number of GPU is {}\".format(n_gpu), LOG_PATH)\n",
        "    for i in range(n_gpu):\n",
        "        write_log((\"Device Name: {},\"\n",
        "                   \"Device Capability: {}\").format(torch.cuda.get_device_name(i),\n",
        "                                                   torch.cuda.get_device_capability(i)), LOG_PATH)\n",
        "\n",
        "    train_file_path = os.path.join(args.data_dir, args.train_data)\n",
        "    val_file_path = os.path.join(args.data_dir, args.val_data)\n",
        "    test_file_path = os.path.join(args.data_dir, args.test_data)\n",
        "    train_df = pd.read_csv(train_file_path)\n",
        "    val_df = pd.read_csv(val_file_path)\n",
        "    test_df = pd.read_csv(test_file_path)\n",
        "\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(args.bert_model, do_lower_case=True)\n",
        "\n",
        "    write_log(\"Tokenize Start!\", LOG_PATH)\n",
        "    train_df = reorder_by_time(train_df)\n",
        "    val_df = reorder_by_time(val_df)\n",
        "    test_df = reorder_by_time(test_df)\n",
        "    train_labels, train_inputs, train_masks, train_note_ids = Tokenize_with_note_id(train_df, MAX_LEN, tokenizer)\n",
        "    validation_labels, validation_inputs, validation_masks, validation_note_ids = Tokenize_with_note_id(val_df, MAX_LEN, tokenizer)\n",
        "    test_labels, test_inputs, test_masks, test_note_ids = Tokenize_with_note_id(test_df, MAX_LEN, tokenizer)\n",
        "    write_log(\"Tokenize Finished!\", LOG_PATH)\n",
        "    train_inputs = torch.tensor(train_inputs)\n",
        "    validation_inputs = torch.tensor(validation_inputs)\n",
        "    test_inputs = torch.tensor(test_inputs)\n",
        "    train_labels = torch.tensor(train_labels)\n",
        "    validation_labels = torch.tensor(validation_labels)\n",
        "    test_labels = torch.tensor(test_labels)\n",
        "    train_masks = torch.tensor(train_masks)\n",
        "    validation_masks = torch.tensor(validation_masks)\n",
        "    test_masks = torch.tensor(test_masks)\n",
        "    write_log((\"train dataset size is %d,\\n\"\n",
        "               \"validation dataset size is %d,\\n\"\n",
        "               \"test dataset size is %d\") % (len(train_inputs), len(validation_inputs), len(test_inputs)), LOG_PATH)\n",
        "\n",
        "    (train_labels, train_inputs,\n",
        "     train_masks, train_ids,\n",
        "     train_note_ids, train_chunk_ids) = concat_by_id_list_with_note_chunk_id(train_df, train_labels,\n",
        "                                                                             train_inputs, train_masks,\n",
        "                                                                             train_note_ids, MAX_LEN)\n",
        "    (validation_labels, validation_inputs,\n",
        "     validation_masks, validation_ids,\n",
        "     validation_note_ids, validation_chunk_ids) = concat_by_id_list_with_note_chunk_id(val_df, validation_labels,\n",
        "                                                                                       validation_inputs,\n",
        "                                                                                       validation_masks,\n",
        "                                                                                       validation_note_ids, MAX_LEN)\n",
        "    (test_labels, test_inputs,\n",
        "     test_masks, test_ids,\n",
        "     test_note_ids, test_chunk_ids) = concat_by_id_list_with_note_chunk_id(test_df, test_labels,\n",
        "                                                                           test_inputs, test_masks,\n",
        "                                                                           test_note_ids, MAX_LEN)\n",
        "\n",
        "    model = BertModel.from_pretrained(args.bert_model).to(device)\n",
        "    patient_model = PatientLevelBertForSequenceClassification(config=config, num_labels=1).to(device)\n",
        "\n",
        "    if n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "        patient_model = torch.nn.DataParallel(patient_model)\n",
        "    param_optimizer = list(model.named_parameters()) + list(patient_model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "    num_train_steps = int(\n",
        "        len(train_labels) / args.gradient_accumulation_steps * args.num_train_epochs)\n",
        "\n",
        "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                         lr=args.learning_rate,\n",
        "                         warmup=args.warmup_proportion,\n",
        "                         t_total=num_train_steps)\n",
        "\n",
        "    start = time.time()\n",
        "    # Store our loss and accuracy for plotting\n",
        "    train_loss_set = []\n",
        "\n",
        "    # Number of training epochs (authors recommend between 2 and 4)\n",
        "    epochs = args.num_train_epochs\n",
        "\n",
        "    train_batch_generator = time_batch_generator(args.max_chunk_num, train_inputs, train_labels, train_masks,\n",
        "                                                 train_note_ids, train_chunk_ids)\n",
        "    validation_batch_generator = time_batch_generator(args.max_chunk_num, validation_inputs, validation_labels,\n",
        "                                                      validation_masks, validation_note_ids, validation_chunk_ids)\n",
        "    write_log(\"Training start!\", LOG_PATH)\n",
        "    # trange is a tqdm wrapper around the normal python range\n",
        "    with torch.autograd.set_detect_anomaly(True):\n",
        "        for epoch in trange(epochs, desc=\"Epoch\"):\n",
        "\n",
        "            # Training\n",
        "\n",
        "            # Set our model to training mode (as opposed to evaluation mode)\n",
        "            model.train()\n",
        "            patient_model.train()\n",
        "\n",
        "            # Tracking variables\n",
        "            tr_loss = 0\n",
        "            nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "            # Train the data for one epoch\n",
        "            tr_ids_num = len(train_ids)\n",
        "            for step in range(tr_ids_num):\n",
        "                b_input_ids, b_labels, b_input_mask, b_note_ids, b_chunk_ids = next(train_batch_generator)\n",
        "                b_input_ids = b_input_ids.to(device)\n",
        "                b_input_mask = b_input_mask.to(device)\n",
        "                b_new_note_ids = convert_note_ids(b_note_ids).to(device)\n",
        "                b_chunk_ids = b_chunk_ids.unsqueeze(0).to(device)\n",
        "                b_labels = b_labels.to(device)\n",
        "                b_labels.resize_((1))\n",
        "                _, whole_output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "                whole_input = whole_output.unsqueeze(0)\n",
        "                b_new_note_ids = b_new_note_ids.unsqueeze(0)\n",
        "                loss, pred = patient_model(whole_input, b_new_note_ids, b_chunk_ids, b_labels)\n",
        "\n",
        "                if n_gpu > 1:\n",
        "                    loss = loss.mean()  # mean() to average on multi-gpu.\n",
        "                train_loss_set.append(loss.item())\n",
        "                # Backward pass\n",
        "                loss.backward()\n",
        "                # Update parameters and take a step using the computed gradient\n",
        "                if (step + 1) % args.train_batch_size == 0:\n",
        "                    optimizer.step()\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                # Update tracking variables\n",
        "                tr_loss += loss.item()\n",
        "                nb_tr_examples += b_input_ids.size(0)\n",
        "                nb_tr_steps += 1\n",
        "\n",
        "            write_log(\"Train loss: {}\".format(tr_loss / nb_tr_steps), LOG_PATH)\n",
        "\n",
        "            # Validation\n",
        "\n",
        "            # Put model in evaluation mode to evaluate loss on the validation set\n",
        "            model.eval()\n",
        "            patient_model.eval()\n",
        "\n",
        "            # Tracking variables\n",
        "            eval_loss, eval_accuracy = 0, 0\n",
        "            nb_eval_steps, nb_eval_examples = 0, 0\n",
        "            # Evaluate data for one epoch\n",
        "            ev_ids_num = len(validation_ids)\n",
        "            for step in range(ev_ids_num):\n",
        "                with torch.no_grad():\n",
        "                    b_input_ids, b_labels, b_input_mask, b_note_ids, b_chunk_ids = next(validation_batch_generator)\n",
        "                    b_input_ids = b_input_ids.to(device)\n",
        "                    b_input_mask = b_input_mask.to(device)\n",
        "                    b_new_note_ids = convert_note_ids(b_note_ids).to(device)\n",
        "                    b_labels.resize_((1))\n",
        "                    _, whole_output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "                    whole_input = whole_output.unsqueeze(0)\n",
        "                    b_new_note_ids = b_new_note_ids.unsqueeze(0)\n",
        "                    pred = patient_model(whole_input, b_new_note_ids, b_chunk_ids).detach().cpu().numpy()\n",
        "                label_ids = b_labels.numpy()\n",
        "                tmp_eval_accuracy = flat_accuracy(pred, label_ids)\n",
        "                eval_accuracy += tmp_eval_accuracy\n",
        "                nb_eval_steps += 1\n",
        "\n",
        "            write_log(\"Validation Accuracy: {}\".format(eval_accuracy / nb_eval_steps), LOG_PATH)\n",
        "            output_checkpoints_path = os.path.join(args.output_dir,\n",
        "                                                   \"bert_fine_tuned_with_note_checkpoint_%d.pt\" % epoch)\n",
        "\n",
        "            if args.save_model:\n",
        "                if n_gpu > 1:\n",
        "                    torch.save({\n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': model.module.state_dict(),\n",
        "                        'patient_model_state_dict': patient_model.module.state_dict(),\n",
        "                        'optimizer_state_dict': optimizer.state_dict(),\n",
        "                        'loss': loss,\n",
        "                    },\n",
        "                        output_checkpoints_path)\n",
        "                else:\n",
        "                    torch.save({\n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                        'patient_model_state_dict': patient_model.state_dict(),\n",
        "                        'optimizer_state_dict': optimizer.state_dict(),\n",
        "                        'loss': loss,\n",
        "                    },\n",
        "                        output_checkpoints_path)\n",
        "    end = time.time()\n",
        "    write_log(\"total training time is: {}s\".format(end - start), LOG_PATH)\n",
        "\n",
        "    fig1 = plt.figure(figsize=(15, 8))\n",
        "    plt.title(\"Training loss\")\n",
        "    plt.xlabel(\"Patient Batch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.plot(train_loss_set)\n",
        "    if args.save_model:\n",
        "        output_fig_path = os.path.join(args.output_dir, \"bert_fine_tuned_with_note_training_loss.png\")\n",
        "        plt.savefig(output_fig_path, dpi=fig1.dpi)\n",
        "\n",
        "        output_model_state_dict_path = os.path.join(args.output_dir, \"bert_fine_tuned_with_note_state_dict.pt\")\n",
        "        if n_gpu > 1:\n",
        "            torch.save({\n",
        "                'model_state_dict': model.module.state_dict(),\n",
        "                'patient_model_state_dict': patient_model.state_dict(),\n",
        "            },\n",
        "                output_model_state_dict_path)\n",
        "        else:\n",
        "            torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'patient_model_state_dict': patient_model.state_dict(),\n",
        "            },\n",
        "                output_model_state_dict_path)\n",
        "        write_log(\"Model saved!\", LOG_PATH)\n",
        "    else:\n",
        "        output_fig_path = os.path.join(args.output_dir,\n",
        "                                       \"bert_fine_tuned_with_note_training_loss_{}_{}.png\".format(args.seed,\n",
        "                                                                                                  args.data_dir.split('_')[-1]))\n",
        "        plt.savefig(output_fig_path, dpi=fig1.dpi)\n",
        "        write_log(\"Model not saved as required\", LOG_PATH)\n",
        "\n",
        "    # Prediction on test set\n",
        "\n",
        "    # Put model in evaluation mode\n",
        "    model.eval()\n",
        "    patient_model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    # Predict\n",
        "    te_ids_num = len(test_ids)\n",
        "    for step in range(te_ids_num):\n",
        "        b_input_ids = test_inputs[step][-args.max_chunk_num:, :].to(device)\n",
        "        b_input_mask = test_masks[step][-args.max_chunk_num:, :].to(device)\n",
        "        b_note_ids = test_note_ids[step][-args.max_chunk_num:]\n",
        "        b_new_note_ids = convert_note_ids(b_note_ids).to(device)\n",
        "        b_chunk_ids = test_chunk_ids[step][-args.max_chunk_num:].unsqueeze(0).to(device)\n",
        "        b_labels = test_labels[step]\n",
        "        b_labels.resize_((1))\n",
        "        with torch.no_grad():\n",
        "            _, whole_output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "            whole_input = whole_output.unsqueeze(0)\n",
        "            b_new_note_ids = b_new_note_ids.unsqueeze(0)\n",
        "            pred = patient_model(whole_input, b_new_note_ids, b_chunk_ids).detach().cpu().numpy()\n",
        "        label_ids = b_labels.numpy()[0]\n",
        "        predictions.append(pred)\n",
        "        true_labels.append(label_ids)\n",
        "\n",
        "    # Flatten the predictions and true values for aggregate Matthew's evaluation on the whole dataset\n",
        "    flat_logits = [item for sublist in predictions for item in sublist]\n",
        "    flat_predictions = np.asarray([1 if i else 0 for i in (np.array(flat_logits) >= 0.5)])\n",
        "    flat_true_labels = np.asarray(true_labels)\n",
        "\n",
        "    output_df = pd.DataFrame({'pred_prob': flat_logits,\n",
        "                              'pred_label': flat_predictions,\n",
        "                              'label': flat_true_labels,\n",
        "                              'Adm_ID': test_ids})\n",
        "\n",
        "    if args.save_model:\n",
        "        output_df.to_csv(os.path.join(args.output_dir, 'test_predictions.csv'), index=False)\n",
        "    else:\n",
        "        output_df.to_csv(os.path.join(args.output_dir,\n",
        "                                      'test_predictions_{}_{}.csv'.format(args.seed,\n",
        "                                                                          args.data_dir.split('_')[-1])), index=False)\n",
        "\n",
        "    write_performance(flat_true_labels, flat_predictions, flat_logits, config, args)"
      ],
      "metadata": {
        "id": "WcTUdpoybLZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The FTL-Trans model proposed in this study."
      ],
      "metadata": {
        "id": "3aQUhy2ebslJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    ## Required parameters\n",
        "    parser.add_argument(\"--data_dir\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\")\n",
        "\n",
        "    parser.add_argument(\"--train_data\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The input training data file name.\"\n",
        "                             \" Should be the .tsv file (or other data file) for the task.\")\n",
        "\n",
        "    parser.add_argument(\"--val_data\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The input validation data file name.\"\n",
        "                             \" Should be the .tsv file (or other data file) for the task.\")\n",
        "\n",
        "    parser.add_argument(\"--test_data\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The input test data file name.\"\n",
        "                             \" Should be the .tsv file (or other data file) for the task.\")\n",
        "\n",
        "    parser.add_argument(\"--log_path\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The log file path.\")\n",
        "\n",
        "    parser.add_argument(\"--output_dir\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The output directory where the model checkpoints will be written.\")\n",
        "\n",
        "    parser.add_argument(\"--save_model\",\n",
        "                        default=False,\n",
        "                        action='store_true',\n",
        "                        help=\"Whether to save the model.\")\n",
        "\n",
        "    parser.add_argument(\"--bert_model\",\n",
        "                        default=\"bert-base-uncased\",\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"Bert pre-trained model selected in the list: bert-base-uncased, \"\n",
        "                             \"bert-large-uncased, bert-base-cased, bert-base-multilingual, bert-base-chinese.\")\n",
        "\n",
        "    parser.add_argument(\"--embed_mode\",\n",
        "                        default=None,\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The embedding type selected in the list: all, note, chunk, no.\")\n",
        "\n",
        "    parser.add_argument(\"--task_name\",\n",
        "                        default=\"FTLSTM_with_ClBERT_mortality\",\n",
        "                        type=str,\n",
        "                        required=True,\n",
        "                        help=\"The name of the task.\")\n",
        "\n",
        "    ## Other parameters\n",
        "    parser.add_argument(\"--max_seq_length\",\n",
        "                        default=128,\n",
        "                        type=int,\n",
        "                        help=\"The maximum total input sequence length after WordPiece tokenization. \\n\"\n",
        "                             \"Sequences longer than this will be truncated, and sequences shorter \\n\"\n",
        "                             \"than this will be padded.\")\n",
        "    parser.add_argument(\"--max_chunk_num\",\n",
        "                        default=64,\n",
        "                        type=int,\n",
        "                        help=\"The maximum total input chunk numbers after WordPiece tokenization.\")\n",
        "    parser.add_argument(\"--train_batch_size\",\n",
        "                        default=1,\n",
        "                        type=int,\n",
        "                        help=\"Total batch size for training.\")\n",
        "    parser.add_argument(\"--eval_batch_size\",\n",
        "                        default=1,\n",
        "                        type=int,\n",
        "                        help=\"Total batch size for eval.\")\n",
        "    parser.add_argument(\"--learning_rate\",\n",
        "                        default=2e-5,\n",
        "                        type=float,\n",
        "                        help=\"The initial learning rate for Adam.\")\n",
        "    parser.add_argument(\"--warmup_proportion\",\n",
        "                        default=0.0,\n",
        "                        type=float,\n",
        "                        help=\"Proportion of training to perform linear learning rate warmup for. \"\n",
        "                             \"E.g., 0.1 = 10%% of training.\")\n",
        "    parser.add_argument(\"--num_train_epochs\",\n",
        "                        default=3,\n",
        "                        type=int,\n",
        "                        help=\"Total number of training epochs to perform.\")\n",
        "    parser.add_argument('--seed',\n",
        "                        type=int,\n",
        "                        default=42,\n",
        "                        help=\"random seed for initialization\")\n",
        "    parser.add_argument('--gradient_accumulation_steps',\n",
        "                        type=int,\n",
        "                        default=1,\n",
        "                        help=\"Number of updates steps to accumualte before performing a backward/update pass.\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.save_model:\n",
        "        raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(args.output_dir))\n",
        "    os.makedirs(args.output_dir, exist_ok=True)\n",
        "\n",
        "    LOG_PATH = args.log_path\n",
        "    MAX_LEN = args.max_seq_length\n",
        "\n",
        "    config = DotMap()\n",
        "    config.hidden_dropout_prob = 0.1\n",
        "    config.layer_norm_eps = 1e-12\n",
        "    config.initializer_range = 0.02\n",
        "    config.max_note_position_embedding = 1000\n",
        "    config.max_chunk_position_embedding = 1000\n",
        "    config.embed_mode = args.embed_mode\n",
        "    config.layer_norm_eps = 1e-12\n",
        "    config.hidden_size = 768\n",
        "    config.lstm_layers = 1\n",
        "\n",
        "    config.task_name = args.task_name\n",
        "\n",
        "    write_log((\"New Job Start! \\n\"\n",
        "               \"Data directory: {}, Directory Code: {}, Save Model: {}\\n\"\n",
        "               \"Output_dir: {}, Task Name: {}, embed_mode: {}\\n\"\n",
        "               \"max_seq_length: {},  max_chunk_num: {}\\n\"\n",
        "               \"train_batch_size: {}, eval_batch_size: {}\\n\"\n",
        "               \"learning_rate: {}, warmup_proportion: {}\\n\"\n",
        "               \"num_train_epochs: {}, seed: {}, gradient_accumulation_steps: {}\\n\"\n",
        "               \"FTLSTM Model's lstm_layers: {}\").format(args.data_dir,\n",
        "                                                        args.data_dir.split('_')[-1],\n",
        "                                                        args.save_model,\n",
        "                                                        args.output_dir,\n",
        "                                                        config.task_name,\n",
        "                                                        config.embed_mode,\n",
        "                                                        args.max_seq_length,\n",
        "                                                        args.max_chunk_num,\n",
        "                                                        args.train_batch_size,\n",
        "                                                        args.eval_batch_size,\n",
        "                                                        args.learning_rate,\n",
        "                                                        args.warmup_proportion,\n",
        "                                                        args.num_train_epochs,\n",
        "                                                        args.seed,\n",
        "                                                        args.gradient_accumulation_steps,\n",
        "                                                        config.lstm_layers),\n",
        "              LOG_PATH)\n",
        "\n",
        "    content = \"config setting: \\n\"\n",
        "    for k, v in config.items():\n",
        "        content += \"{}: {} \\n\".format(k, v)\n",
        "    write_log(content, LOG_PATH)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "    write_log(\"Number of GPU is {}\".format(n_gpu), LOG_PATH)\n",
        "    for i in range(n_gpu):\n",
        "        write_log((\"Device Name: {},\"\n",
        "                   \"Device Capability: {}\").format(torch.cuda.get_device_name(i),\n",
        "                                                   torch.cuda.get_device_capability(i)), LOG_PATH)\n",
        "\n",
        "    train_file_path = os.path.join(args.data_dir, args.train_data)\n",
        "    val_file_path = os.path.join(args.data_dir, args.val_data)\n",
        "    test_file_path = os.path.join(args.data_dir, args.test_data)\n",
        "    train_df = pd.read_csv(train_file_path)\n",
        "    val_df = pd.read_csv(val_file_path)\n",
        "    test_df = pd.read_csv(test_file_path)\n",
        "\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(args.bert_model, do_lower_case=True)\n",
        "\n",
        "    write_log(\"Tokenize Start!\", LOG_PATH)\n",
        "    train_df = reorder_by_time(train_df)\n",
        "    val_df = reorder_by_time(val_df)\n",
        "    test_df = reorder_by_time(test_df)\n",
        "    train_labels, train_inputs, train_masks, train_note_ids, train_times = Tokenize_with_note_id_hour(train_df, MAX_LEN,\n",
        "                                                                                                      tokenizer)\n",
        "    validation_labels, validation_inputs, validation_masks, validation_note_ids, validation_times = Tokenize_with_note_id_hour(\n",
        "        val_df, MAX_LEN, tokenizer)\n",
        "    test_labels, test_inputs, test_masks, test_note_ids, test_times = Tokenize_with_note_id_hour(test_df, MAX_LEN,\n",
        "                                                                                                 tokenizer)\n",
        "    write_log(\"Tokenize Finished!\", LOG_PATH)\n",
        "    train_inputs = torch.tensor(train_inputs)\n",
        "    validation_inputs = torch.tensor(validation_inputs)\n",
        "    test_inputs = torch.tensor(test_inputs)\n",
        "    train_labels = torch.tensor(train_labels)\n",
        "    validation_labels = torch.tensor(validation_labels)\n",
        "    test_labels = torch.tensor(test_labels)\n",
        "    train_masks = torch.tensor(train_masks)\n",
        "    validation_masks = torch.tensor(validation_masks)\n",
        "    test_masks = torch.tensor(test_masks)\n",
        "    train_times = torch.tensor(train_times)\n",
        "    validation_times = torch.tensor(validation_times)\n",
        "    test_times = torch.tensor(test_times)\n",
        "    write_log((\"train dataset size is %d,\\n\"\n",
        "               \"validation dataset size is %d,\\n\"\n",
        "               \"test dataset size is %d\") % (len(train_inputs), len(validation_inputs), len(test_inputs)), LOG_PATH)\n",
        "\n",
        "    (train_labels, train_inputs,\n",
        "     train_masks, train_ids,\n",
        "     train_note_ids, train_chunk_ids, train_times) = concat_by_id_list_with_note_chunk_id_time(train_df, train_labels,\n",
        "                                                                                               train_inputs,\n",
        "                                                                                               train_masks,\n",
        "                                                                                               train_note_ids,\n",
        "                                                                                               train_times, MAX_LEN)\n",
        "    (validation_labels, validation_inputs,\n",
        "     validation_masks, validation_ids,\n",
        "     validation_note_ids, validation_chunk_ids,\n",
        "     validation_times) = concat_by_id_list_with_note_chunk_id_time(val_df, validation_labels,\n",
        "                                                                   validation_inputs, validation_masks,\n",
        "                                                                   validation_note_ids, validation_times,\n",
        "                                                                   MAX_LEN)\n",
        "    (test_labels, test_inputs,\n",
        "     test_masks, test_ids,\n",
        "     test_note_ids, test_chunk_ids, test_times) = concat_by_id_list_with_note_chunk_id_time(test_df, test_labels,\n",
        "                                                                                            test_inputs, test_masks,\n",
        "                                                                                            test_note_ids, test_times,\n",
        "                                                                                            MAX_LEN)\n",
        "\n",
        "    model = BertModel.from_pretrained(args.bert_model).to(device)\n",
        "    model.to(device)\n",
        "    lstm_layer = FTLSTMLayer(config=config, num_labels=1)\n",
        "    lstm_layer.to(device)\n",
        "\n",
        "    if n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "        lstm_layer = torch.nn.DataParallel(lstm_layer)\n",
        "    param_optimizer = list(model.named_parameters()) + list(lstm_layer.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "\n",
        "    num_train_steps = int(\n",
        "        len(train_labels) / args.gradient_accumulation_steps * args.num_train_epochs)\n",
        "\n",
        "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                         lr=args.learning_rate,\n",
        "                         warmup=args.warmup_proportion,\n",
        "                         t_total=num_train_steps)\n",
        "    start = time.time()\n",
        "    # Store our loss and accuracy for plotting\n",
        "    train_loss_set = []\n",
        "\n",
        "    # Number of training epochs (authors recommend between 2 and 4)\n",
        "    epochs = args.num_train_epochs\n",
        "\n",
        "    train_batch_generator = time_batch_generator(args.max_chunk_num, train_inputs, train_labels, train_masks,\n",
        "                                                 train_note_ids, train_chunk_ids, train_times)\n",
        "    validation_batch_generator = time_batch_generator(args.max_chunk_num, validation_inputs, validation_labels,\n",
        "                                                      validation_masks, validation_note_ids, validation_chunk_ids,\n",
        "                                                      validation_times)\n",
        "\n",
        "    write_log(\"Training start!\", LOG_PATH)\n",
        "    # trange is a tqdm wrapper around the normal python range\n",
        "    with torch.autograd.set_detect_anomaly(False):\n",
        "        for epoch in trange(epochs, desc=\"Epoch\"):\n",
        "\n",
        "            # Training\n",
        "\n",
        "            # Set our model to training mode (as opposed to evaluation mode)\n",
        "            model.train()\n",
        "            lstm_layer.train()\n",
        "\n",
        "            # Tracking variables\n",
        "            tr_loss = 0\n",
        "            nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "            # Train the data for one epoch\n",
        "            tr_ids_num = len(train_ids)\n",
        "            tr_batch_loss = []\n",
        "            for step in range(tr_ids_num):\n",
        "                b_input_ids, b_labels, b_input_mask, b_note_ids, b_chunk_ids, b_times = next(train_batch_generator)\n",
        "                b_input_ids = b_input_ids.to(device)\n",
        "                b_input_mask = b_input_mask.to(device)\n",
        "                b_new_note_ids = convert_note_ids(b_note_ids).to(device)\n",
        "                b_chunk_ids = b_chunk_ids.unsqueeze(0).to(device)\n",
        "                b_labels = b_labels.to(device)\n",
        "                b_labels.resize_((1))\n",
        "                _, whole_output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "                whole_input = whole_output.unsqueeze(0)\n",
        "                b_new_note_ids = b_new_note_ids.unsqueeze(0)\n",
        "                b_times = b_times.unsqueeze(0).to(device)\n",
        "                loss, pred = lstm_layer(whole_input, b_times, b_new_note_ids, b_chunk_ids, b_labels)\n",
        "\n",
        "                if n_gpu > 1:\n",
        "                    loss = loss.mean()  # mean() to average on multi-gpu.\n",
        "                tr_batch_loss.append(loss.item())\n",
        "\n",
        "                # Backward pass\n",
        "                loss.backward()\n",
        "                # Update parameters and take a step using the computed gradient\n",
        "                if (step + 1) % args.train_batch_size == 0:\n",
        "                    optimizer.step()\n",
        "                    optimizer.zero_grad()\n",
        "                    train_loss_set.append(np.mean(tr_batch_loss))\n",
        "                    tr_batch_loss = []\n",
        "                # Update tracking variables\n",
        "                tr_loss += loss.item()\n",
        "                nb_tr_examples += b_input_ids.size(0)\n",
        "                nb_tr_steps += 1\n",
        "\n",
        "            write_log(\"Train loss: {}\".format(tr_loss / nb_tr_steps), LOG_PATH)\n",
        "            # Validation\n",
        "\n",
        "            # Put model in evaluation mode to evaluate loss on the validation set\n",
        "            model.eval()\n",
        "            lstm_layer.eval()\n",
        "\n",
        "            # Tracking variables\n",
        "            eval_loss, eval_accuracy = 0, 0\n",
        "            nb_eval_steps, nb_eval_examples = 0, 0\n",
        "            # Evaluate data for one epoch\n",
        "            ev_ids_num = len(validation_ids)\n",
        "            for step in range(ev_ids_num):\n",
        "                with torch.no_grad():\n",
        "                    b_input_ids, b_labels, b_input_mask, b_note_ids, b_chunk_ids, b_times = next(\n",
        "                        validation_batch_generator)\n",
        "                    b_input_ids = b_input_ids.to(device)\n",
        "                    b_input_mask = b_input_mask.to(device)\n",
        "                    b_new_note_ids = convert_note_ids(b_note_ids).to(device)\n",
        "                    b_chunk_ids = b_chunk_ids.unsqueeze(0).to(device)\n",
        "                    b_labels.resize_((1))\n",
        "                    _, whole_output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "                    whole_input = whole_output.unsqueeze(0)\n",
        "                    b_new_note_ids = b_new_note_ids.unsqueeze(0)\n",
        "                    b_times = b_times.unsqueeze(0).to(device)\n",
        "                    pred = lstm_layer(whole_input, b_times, b_new_note_ids, b_chunk_ids).detach().cpu().numpy()\n",
        "                label_ids = b_labels.numpy()\n",
        "                tmp_eval_accuracy = flat_accuracy(pred, label_ids)\n",
        "                eval_accuracy += tmp_eval_accuracy\n",
        "                nb_eval_steps += 1\n",
        "\n",
        "            write_log(\"Validation Accuracy: {}\".format(eval_accuracy / nb_eval_steps), LOG_PATH)\n",
        "            output_checkpoints_path = os.path.join(args.output_dir,\n",
        "                                                   \"bert_fine_tuned_with_note_checkpoint_%d.pt\" % epoch)\n",
        "\n",
        "            if args.save_model:\n",
        "                if n_gpu > 1:\n",
        "                    torch.save({\n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': model.module.state_dict(),\n",
        "                        'lstm_layer_state_dict': lstm_layer.module.state_dict(),\n",
        "                        'optimizer_state_dict': optimizer.state_dict(),\n",
        "                        'loss': loss,\n",
        "                    },\n",
        "                        output_checkpoints_path)\n",
        "                else:\n",
        "                    torch.save({\n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                        'lstm_layer_state_dict': lstm_layer.state_dict(),\n",
        "                        'optimizer_state_dict': optimizer.state_dict(),\n",
        "                        'loss': loss,\n",
        "                    },\n",
        "                        output_checkpoints_path)\n",
        "    end = time.time()\n",
        "    write_log(\"total training time is: {}s\".format(end - start), LOG_PATH)\n",
        "\n",
        "    fig1 = plt.figure(figsize=(15, 8))\n",
        "    plt.title(\"Training loss\")\n",
        "    plt.xlabel(\"Patient Batch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.plot(train_loss_set)\n",
        "    if args.save_model:\n",
        "        output_fig_path = os.path.join(args.output_dir, \"bert_fine_tuned_with_note_training_loss.png\")\n",
        "        plt.savefig(output_fig_path, dpi=fig1.dpi)\n",
        "        output_model_state_dict_path = os.path.join(args.output_dir, \"bert_fine_tuned_with_note_state_dict.pt\")\n",
        "        if n_gpu > 1:\n",
        "            torch.save({\n",
        "                'model_state_dict': model.module.state_dict(),\n",
        "                'lstm_layer_state_dict': lstm_layer.module.state_dict(),\n",
        "            },\n",
        "                output_model_state_dict_path)\n",
        "        else:\n",
        "            torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'lstm_layer_state_dict': lstm_layer.state_dict(),\n",
        "            },\n",
        "                output_model_state_dict_path)\n",
        "        write_log(\"Model saved!\", LOG_PATH)\n",
        "    else:\n",
        "        output_fig_path = os.path.join(args.output_dir,\n",
        "                                       \"bert_fine_tuned_with_note_training_loss_{}_{}.png\".format(args.seed,\n",
        "                                                                                                  args.data_dir.split(\n",
        "                                                                                                      '_')[-1]))\n",
        "        plt.savefig(output_fig_path, dpi=fig1.dpi)\n",
        "        write_log(\"Model not saved as required\", LOG_PATH)\n",
        "\n",
        "    # Prediction on test set\n",
        "\n",
        "    # Put model in evaluation mode\n",
        "    model.eval()\n",
        "    lstm_layer.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    # Predict\n",
        "    te_ids_num = len(test_ids)\n",
        "    for step in range(te_ids_num):\n",
        "        b_input_ids = test_inputs[step][-args.max_chunk_num:, :].to(device)\n",
        "        b_input_mask = test_masks[step][-args.max_chunk_num:, :].to(device)\n",
        "        b_note_ids = test_note_ids[step][-args.max_chunk_num:]\n",
        "        b_new_note_ids = convert_note_ids(b_note_ids).to(device)\n",
        "        b_chunk_ids = test_chunk_ids[step][-args.max_chunk_num:].unsqueeze(0).to(device)\n",
        "        b_labels = test_labels[step]\n",
        "        b_labels.resize_((1))\n",
        "        with torch.no_grad():\n",
        "            _, whole_output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "            whole_input = whole_output.unsqueeze(0)\n",
        "            b_new_note_ids = b_new_note_ids.unsqueeze(0)\n",
        "            b_times = test_times[step][-args.max_chunk_num:].unsqueeze(0).to(device)\n",
        "            pred = lstm_layer(whole_input, b_times, b_new_note_ids, b_chunk_ids).detach().cpu().numpy()\n",
        "        label_ids = b_labels.numpy()[0]\n",
        "        predictions.append(pred)\n",
        "        true_labels.append(label_ids)\n",
        "\n",
        "    # Flatten the predictions and true values for aggregate Matthew's evaluation on the whole dataset\n",
        "    flat_logits = [item for sublist in predictions for item in sublist]\n",
        "    flat_predictions = np.asarray([1 if i else 0 for i in (np.array(flat_logits) >= 0.5)])\n",
        "    flat_true_labels = np.asarray(true_labels)\n",
        "\n",
        "    output_df = pd.DataFrame({'pred_prob': flat_logits,\n",
        "                              'pred_label': flat_predictions,\n",
        "                              'label': flat_true_labels,\n",
        "                              'Adm_ID': test_ids})\n",
        "\n",
        "    if args.save_model:\n",
        "        output_df.to_csv(os.path.join(args.output_dir, 'test_predictions.csv'), index=False)\n",
        "    else:\n",
        "        output_df.to_csv(os.path.join(args.output_dir,\n",
        "                                      'test_predictions_{}_{}.csv'.format(args.seed,\n",
        "                                                                          args.data_dir.split('_')[-1])), index=False)\n",
        "\n",
        "    write_performance(flat_true_labels, flat_predictions, flat_logits, config, args)"
      ],
      "metadata": {
        "id": "FPmRcANYbxYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "In this section, you should finish training your model training or loading your trained model. That is a great experiment! You should share the results with others with necessary metrics and figures.\n",
        "\n",
        "Please test and report results for all experiments that you run with:\n",
        "\n",
        "*   specific numbers (accuracy, AUC, RMSE, etc)\n",
        "*   figures (loss shrinkage, outputs from GAN, annotation or label of sample pictures, etc)\n"
      ],
      "metadata": {
        "id": "gX6bCcZNuxmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# metrics to evaluate my model\n",
        "\n",
        "# plot figures to better show the results\n",
        "\n",
        "# it is better to save the numbers and figures for your presentation."
      ],
      "metadata": {
        "id": "LjW9bCkouv8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model comparison"
      ],
      "metadata": {
        "id": "8EAWAy_LwHlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compare you model with others\n",
        "# you don't need to re-run all other experiments, instead, you can directly refer the metrics/numbers in the paper"
      ],
      "metadata": {
        "id": "uOdhGrbwwG71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion\n",
        "\n",
        "In this section,you should discuss your work and make future plan. The discussion should address the following questions:\n",
        "  * Make assessment that the paper is reproducible or not.\n",
        "  * Explain why it is not reproducible if your results are kind negative.\n",
        "  * Describe “What was easy” and “What was difficult” during the reproduction.\n",
        "  * Make suggestions to the author or other reproducers on how to improve the reproducibility.\n",
        "  * What will you do in next phase.\n",
        "\n"
      ],
      "metadata": {
        "id": "qH75TNU71eRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# no code is required for this section\n",
        "'''\n",
        "if you want to use an image outside this notebook for explanaition,\n",
        "you can read and plot it here like the Scope of Reproducibility\n",
        "'''"
      ],
      "metadata": {
        "id": "E2VDXo5F4Frm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "[1] Zhang, D., Thadajarassiri, J., Sen, C., & Rundensteiner, E. (2020). Time-Aware Transformer-based Network for Clinical Notes Series Prediction. *Proceedings of Machine Learning Research*, 126, 1-22.\n",
        "\n",
        "[2] Huang, K., Altosaar, J., & Ranganath, R. (2019). ClinicalBERT: Modeling Clinical Notes and Predicting Hospital Readmission. ArXiv, abs/1904.05342.\n",
        "\n",
        "[3] Johnson, A. E. W., Pollard, T. J., Shen, L., Li-wei, H. L., Feng, M., Ghassemi, M., ... & Mark, R. G. (2016). MIMIC-III, a freely accessible critical care database. *Scientific data*, 3(1), 1-9.\n",
        "\n"
      ],
      "metadata": {
        "id": "SHMI2chl9omn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feel free to add new sections"
      ],
      "metadata": {
        "id": "xmVuzQ724HbO"
      }
    }
  ]
}